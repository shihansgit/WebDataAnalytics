{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# EDGAR - Reading Information Tables in Text Format - Advanced Text Mining (25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### So far, we have collected CIKs for each of the Mutual Funds, then looked up the links of all the 13F HRs and the Information Tables, and identified them either text tables or xml tables. In class, we  obtained the information from the xml tables.  In this assignment we will obtain information from the text file.  These are not as nicely structured as the xml output.   In a csv (HW_Mutual_Fund_Info_Table_Link.csv) you will find a few of these links.  Your goal for this part of the homework is to obtain the link to the text files from the attached file  (HW_Mutual_Fund_Info_Table_Link.csv).  Then you will write a code that will go to the links of all the linked text files, and extract some columns.  Do not use Beutiful Soup for this assignment.   We provide some initial code to guide your initial steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### First we have to collect the links of the text Info Tables in lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "text_link = []\n",
    "text_Name = []\n",
    "text_date = []\n",
    "\n",
    "input_file = open('/home/jovyan/OneDrive/DESKTOP/HW_Mutual_Fund_Info_Table_Link.csv', 'r')\n",
    "\n",
    "rows = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "for item in range(1,len(rows)):\n",
    "    columns = rows[item].split(',')\n",
    "    if columns[4] == 'text':\n",
    "        text_link.append(columns[3])\n",
    "        text_Name.append(columns[1])\n",
    "        text_date.append(columns[2])\n",
    "\n",
    "# Your Code on Enumerating the Lists.  The result should be three lists, text_link, text_Name,\n",
    "#and text_date.  Each should have length 122."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Keep only the links that correspond to a date after 2010 (Don't inlude 2010, start at 2011).  Hint: you can use the datetime library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Use the following list to store the filtered values.\n",
    "filtered_dates = []\n",
    "filtered_name = []\n",
    "filtered_link = []\n",
    "\n",
    "#Enter code here to to keep only the dates corresponding to after 2010.  \n",
    "\n",
    "start_date = datetime.strptime('2010-12-31', '%Y-%m-%d')\n",
    "for item in rows[1:]:\n",
    "    columns = item.split(',')\n",
    "    year = datetime.strptime(columns[2], '%Y-%m-%d').year\n",
    "    if columns[4] == 'text' and year > 2010:\n",
    "        filtered_link.append('https://www.sec.gov' + columns[3])\n",
    "        filtered_name.append(columns[1])\n",
    "        filtered_dates.append(columns[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your filtered list should now have 8 elements. These represent 3 mutual funds. The first one has CIK=1311981 (from the link you can find this at data/1311981 ). The second was has CIK 813470. The third one has CIK 1432353.\n",
    "['https://www.sec.gov/Archives/edgar/data/1311981/000116204413000513/0001162044-13-000513.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347013000006/0000813470-13-000006.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347013000001/0000813470-13-000001.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347012000023/0000813470-12-000023.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347012000019/0000813470-12-000019.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347012000014/0000813470-12-000014.txt ', 'https://www.sec.gov/Archives/edgar/data/813470/000081347012000003/0000813470-12-000003.txt ', 'https://www.sec.gov/Archives/edgar/data/1432353/000114420411008428/0001144204-11-008428.txt ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Next, for each text link, extract the name of issuer, CUSIP, and the Quantity of shares.  You will also want to keep track of the mutual fund name as well as the filing report date.  \n",
    "\n",
    "#### Your output file should have 5 columns.  The first is the issue date of the form which can be found in the filtered_date list (this will be repeated for the same form).  The second is the mutual fund name which can be found in the filtered_name list (this will be repeated).  The third, fourth and fifith are the name of issuer, CUSIP, and shares respectively.  Make sure to account for the fact that while some of the text files have the same formatting, others do not.  This means you will have to look through them to make sure your code works for the each text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Finally, you write down the lists in the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "\n",
    "issue_date = []\n",
    "mutual_fund_name = [] \n",
    "name_of_issuer = [] \n",
    "CUSIP = [] # CUSIP number\n",
    "shares = [] # No. of Shares of the company in the Mutual Fund\n",
    "for index in range(len(filtered_link)):\n",
    "    url = filtered_link[index]\n",
    "    txt = urllib.request.urlopen(url)\n",
    "    txtLines = txt.readlines()\n",
    "    table_flag = False\n",
    "    columns_flag = False\n",
    "    start_index = []\n",
    "    for i in range(len(txtLines)):\n",
    "        line = txtLines[i].decode(\"utf-8\") \n",
    "        if line.find(\"<CAPTION>\") > -1:\n",
    "            table_flag = True\n",
    "            continue\n",
    "        if line.find(\"</TABLE>\") > -1:\n",
    "            table_flag = False\n",
    "            columns_flag = False\n",
    "            continue\n",
    "        if table_flag:\n",
    "            if columns_flag:\n",
    "                if line[0] != ' ' and line[0] != '-' and line.find('NAME OF ISSUER') < 0:\n",
    "                    if len(line.split()) < 2:\n",
    "                        continue\n",
    "                    issue_date.append(filtered_dates[index])\n",
    "                    mutual_fund_name.append(filtered_name[index])\n",
    "                    name_of_issuer.append(line[:start_index[1]].strip())\n",
    "                    CUSIP.append(line[start_index[2]: start_index[3]])\n",
    "                    shares.append(line[start_index[4]: start_index[5]])\n",
    "            if line.find(\"<C>\") > -1:\n",
    "                start_index = []\n",
    "                parttern = \"<\\w>\"\n",
    "                columns = re.finditer(parttern, line)\n",
    "                for match in columns:\n",
    "                    start_index.append(match.start())\n",
    "                columns_flag = True\n",
    "                continue\n",
    "result = []\n",
    "finalHeader = ['issue date', 'mutual fund name', 'name of issuer', 'CUSIP', 'shares']\n",
    "headerLine = '\\t'.join(finalHeader)\n",
    "result.append(headerLine)\n",
    "for i in range(len(issue_date)):\n",
    "    entryLine = '\\t'.join([\n",
    "                str(issue_date[i]),\n",
    "                str(mutual_fund_name[i]),\n",
    "                str(name_of_issuer[i]),\n",
    "                str(CUSIP[i]),\n",
    "                str(shares[i])\n",
    "            ])\n",
    "    result.append(entryLine)\n",
    "with open('./output.txt', 'a+') as f:\n",
    "    for item in result:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
